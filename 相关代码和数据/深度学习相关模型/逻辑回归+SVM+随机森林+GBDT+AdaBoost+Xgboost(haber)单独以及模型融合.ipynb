{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report as report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier,RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/hiber_train.csv', header = None)\n",
    "data=df.values[1:]\n",
    "data=data.astype(float)\n",
    "X_train=data[:,0:3]\n",
    "y_train=data[:,3]\n",
    "y_train=y_train.astype(int)\n",
    "\n",
    "df = pd.read_csv('data/hiber_test.csv', header = None)\n",
    "data=df.values[1:]\n",
    "data=data.astype(float)\n",
    "X_test=data[:,0:3]\n",
    "y_test=data[:,3]\n",
    "y_test=y_test.astype(int)\n",
    "\n",
    "\n",
    "# y_train = tf.one_hot(y_train,10)\n",
    "# y_test = tf.one_hot(y_test,10)\n",
    "# sess1=tf.Session()\n",
    "# y_train, y_test = sess1.run([y_train,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf=LogisticRegression(max_iter=3000)\n",
    "svm_clf=SVC()\n",
    "rf_clf=RandomForestClassifier(\n",
    "    n_estimators=21,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=4,\n",
    "    random_state=0)\n",
    "\n",
    "gbr = GradientBoostingClassifier(n_estimators=30000, max_depth=2, min_samples_split=2, learning_rate=0.01)\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=None, min_samples_split=20, min_samples_leaf=21),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200, learning_rate=0.8)\n",
    "xgb = XGBClassifier(learning_rate=0.01,max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(X_train,y_train)\n",
    "svm_clf.fit(X_train,y_train)\n",
    "rf_clf.fit(X_train,y_train)\n",
    "gbr.fit(X_train, y_train.ravel())\n",
    "bdt.fit(X_train,y_train)\n",
    "eval_set = [(X_test, y_test)]\n",
    "xgb.fit(X_train, y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred=lr_clf.predict(X_test)\n",
    "svm_pred=svm_clf.predict(X_test)\n",
    "rf_pred=rf_clf.predict(X_test)\n",
    "gbr_pred = gbr.predict(X_test)\n",
    "bdt_pred = bdt.predict(X_test)\n",
    "xgb_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.98      0.86        45\n",
      "           2       0.75      0.19      0.30        16\n",
      "\n",
      "    accuracy                           0.77        61\n",
      "   macro avg       0.76      0.58      0.58        61\n",
      "weighted avg       0.77      0.77      0.72        61\n",
      "\n",
      "svm:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      1.00      0.85        45\n",
      "           2       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.74        61\n",
      "   macro avg       0.37      0.50      0.42        61\n",
      "weighted avg       0.54      0.74      0.63        61\n",
      "\n",
      "rf:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.98      0.86        45\n",
      "           2       0.75      0.19      0.30        16\n",
      "\n",
      "    accuracy                           0.77        61\n",
      "   macro avg       0.76      0.58      0.58        61\n",
      "weighted avg       0.77      0.77      0.72        61\n",
      "\n",
      "GBDT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.91      0.82        45\n",
      "           2       0.33      0.12      0.18        16\n",
      "\n",
      "    accuracy                           0.70        61\n",
      "   macro avg       0.54      0.52      0.50        61\n",
      "weighted avg       0.64      0.70      0.65        61\n",
      "\n",
      "AdaBoost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.91      0.85        45\n",
      "           2       0.56      0.31      0.40        16\n",
      "\n",
      "    accuracy                           0.75        61\n",
      "   macro avg       0.67      0.61      0.62        61\n",
      "weighted avg       0.73      0.75      0.73        61\n",
      "\n",
      "XgBoost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.93      0.83        45\n",
      "           2       0.40      0.12      0.19        16\n",
      "\n",
      "    accuracy                           0.72        61\n",
      "   macro avg       0.57      0.53      0.51        61\n",
      "weighted avg       0.66      0.72      0.66        61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('lr:\\n',report(y_test,lr_pred))\n",
    "print('svm:\\n',report(y_test,svm_pred))\n",
    "print('rf:\\n',report(y_test, rf_pred))\n",
    "print('GBDT:\\n',report(y_test, gbr_pred))\n",
    "print('AdaBoost:\\n',report(y_test, bdt_pred))\n",
    "print('XgBoost:\\n',report(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "esb_clf=VotingClassifier(estimators=[\n",
    "    ('rf_clf',rf_clf),\n",
    "    ('svm_clf',SVC(probability=True)),\n",
    "    ('lr_clf',lr_clf),\n",
    "    ('GBDT',gbr),\n",
    "    ('AdaBoost',bdt),\n",
    "    ('Xgboost',xgb)\n",
    "    ],\n",
    "    weights=[1,0.7,1,0.7,0.7,0.7],\n",
    "    voting='soft')\n",
    "esb_clf2=VotingClassifier(estimators=[\n",
    "    ('rf_clf',rf_clf),\n",
    "    ('svm_clf',SVC(probability=True)),\n",
    "    ('lr_clf',lr_clf),\n",
    "    ('GBDT',gbr),\n",
    "    ('AdaBoost',bdt),\n",
    "    ('Xgboost',xgb)],\n",
    "    weights=[1,0.6,0.7,0.7,0.9,0.9],\n",
    "    voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "esb_clf.fit(X_train,y_train)\n",
    "esb_pred=esb_clf.predict(X_test)\n",
    "esb_clf2.fit(X_train,y_train)\n",
    "esb_pred2=esb_clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble-soft:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.98      0.85        45\n",
      "           2       0.67      0.12      0.21        16\n",
      "\n",
      "    accuracy                           0.75        61\n",
      "   macro avg       0.71      0.55      0.53        61\n",
      "weighted avg       0.73      0.75      0.69        61\n",
      "\n",
      "ensemble-hard:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.96      0.85        45\n",
      "           2       0.60      0.19      0.29        16\n",
      "\n",
      "    accuracy                           0.75        61\n",
      "   macro avg       0.68      0.57      0.57        61\n",
      "weighted avg       0.72      0.75      0.70        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('ensemble-soft:\\n',report(y_test,esb_pred))\n",
    "print('ensemble-hard:\\n',report(y_test,esb_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
